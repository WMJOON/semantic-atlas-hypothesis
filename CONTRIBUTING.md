# Contributing to Semantic Atlas Hypothesis

Thank you for your interest in contributing!

This repository is intended as a **working hypothesis** and open framework to explore how meaning emerges in information-rich contexts and how AI systems should be structured with respect to human cognition.

## What to contribute

- Clarifications or corrections of existing definitions
- Examples from real-world AI systems (LLM/agent workflows, evaluation, interpretability)
- Case studies showing interpretation breakdowns (meaning collapse / judgment deferral)
- Physical AI domain observations (control â†” judgment boundary)
- Alternative formulations of Atlas / local charts (coordinate systems of understanding)
- Diagrams that make relationships easier to see

## What this repository is NOT

- A finalized theory
- A specification for production AI systems
- A ground-truth claim about cognition

## How to contribute

1. Open an issue describing your idea (problem statement + what you propose to change)
2. Discuss the refinement in the thread (scope, terminology, placement)
3. Submit a pull request with revisions

## Writing & structure conventions

- Language: Korean and/or English are both welcome. Prefer bilingual titles where helpful.
- Keep claims falsifiable when possible; label speculative parts explicitly.
- For new terms, add a short definition in `Docs/Glossary.md` (and optionally a brief mention in `README.md`).
- For new case studies, use the template in `Examples/CASE_TEMPLATE.md`.

## License

By contributing, you agree that your contributions will be licensed under the repository license in `LICENSE` (CC BY-SA 4.0).

